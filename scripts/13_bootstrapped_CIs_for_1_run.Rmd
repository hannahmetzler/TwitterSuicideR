---
title: "ML metrics"
author: "Hannah Metzler"
date: "16/11/2021"
output: 
  pdf_document:
    df_print: kable
    keep_tex: true
url_colour: blue
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
Sys.setlocale("LC_ALL", 'en_US.UTF-8')
options(scipen=99)
library(dplyr)
library(caret)
# library(epiR)
library(boot)

#function for calculating bootstrapped CIs: 
# intro to boot package: https://www.geeksforgeeks.org/bootstrap-confidence-interval-with-r-programming/
#function to calculate the statistics precision, recall, F1, accuracy for each of the 6 categories
mlperf6.fun = function(data, idx, class){
  df <- data[idx, ]
  #out of the confusion Matrix, we only select the byClass metrics, here for only one class at a time
  perf_class = confusionMatrix(df$true_label, df$predicted_label)$byClass[paste("Class:", class), 
                                                                          c("Precision", "Recall", "F1")]
  return(perf_class)
}

#accuracy per class function
acc.fun= function(data, idx, class){
  df <- data[idx, ]
  Acc = df %>% 
    summarise(df, sum(predicted_label==true_label)/n())
  return(Acc)
}
data = test_6cat
data = filter(data, true_label==iclass)
bootstrap = boot(data, acc.fun, class=iclass, R=1000)
#this accuracy function still throws an error, check

#order of levels, function: 
order_cat = c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant" )
order6cat = function(df){
    df = df %>% 
      mutate(true_label = factor(true_label, labels=order_cat, levels=order_cat), 
      predicted_label = factor(predicted_label, labels=order_cat, levels=order_cat))
    return(df)
}

#function to calculate the statistics for each of the 2 about suicide categories
mlperf2.fun = function(data, idx, class){
  df <- data[idx, ]
   #out of the confusion Matrix, we only select the byClass metrics, here for only one class at a time
  perf_class = confusionMatrix(df$true_label, df$predicted_label, positive=iclass)$byClass[c("Precision", "Recall", "F1")]

  return(perf_class)
}
```


# BERT: Performance scores with boostrapped confidence intervals

Used resources to calculate CIs: 
* intro to boot package: https://www.geeksforgeeks.org/bootstrap-confidence-interval-with-r-programming/
* on the boot package with multiple statistics at once (Precision, Recall, F1): https://stackoverflow.com/questions/51371307/obtaining-plots-and-95-cis-from-boot-function-with-multiple-statistics

* We eventually did not use this for the paper, because we only had saved predicted/true labels for one run for XLNet and BERT, and performance across runs really differs for some categories (see e.g. suicidality, usually precision around 0.6, but one run only .46)
* Instead, we calculate Chi square based confidence intervals on the average performance scores across runs (see script 10).


```{r, read in datafiles BERT}
val_6cat = order6cat(read.csv('../results/predictions_BERT_6_classes_validation_set_notext.csv'))
test_6cat = order6cat(read.csv('../results/predictions_BERT_6_classes_test_set_notext.csv'))
val_aboutsuicide = read.csv('../results/predictions_BERT_about_suicide_validation_set_notext.csv')
test_aboutsuicide = read.csv('../results/predictions_BERT_about_suicide_test_set_notext.csv')
```

## 6 categories

### BERT test set

```{r}
#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 6, ncol = 9), row.names =c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant"))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  
#now run the bootstrap and calculate CIs for each class
for(iclass in c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant")){
 
  data = test_6cat
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(data, mlperf6.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
  
  #Accuracy per class
  bootstrap = boot(data, acc.fun, class="coping", R=1000)
  Acc = acc.fun(data, class="coping")

  
}

df["macro",] = colMeans(df)
df



cis_BERT_6cat_test = df
write.csv(cis_BERT_6cat_test, "../results/cis_BERT_6cat_test.csv")
```

### BERT validation set

```{r}
#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 6, ncol = 9), row.names =c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant"))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  
#now run the bootstrap and calculate CIs for each class
for(iclass in c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant")){
 
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(val_6cat, mlperf6.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
}
df["macro",] = colMeans(df)
df
cis_BERT_6cat_validation = df
write.csv(cis_BERT_6cat_validation, "../results/cis_BERT_6cat_validation.csv")
```

```{r}
#format to paste into tables in paper: the macro averages tables 3 and 5: validation set | test set, one metric per column
# test set
cis_BERT_6cat_test = round(cis_BERT_6cat_test, 2)
macro = cis_BERT_6cat_test["macro",]
#empty dataframe with colume names
macrotab = data.frame(matrix(NA, nrow = 1, ncol = 4))
names(macrotab ) = c("Pr", "Re", "F1", "Acc")
#paste the precision and its CI values into one cell, then same for recall and F1
macrotab$Pr = paste0(macro$Precision, " [", macro$PrCiLow, ",", macro$PrCiUp, "]")
macrotab$Re = paste0(macro$Recall, " [", macro$ReCiLow, ",", macro$ReCiUp, "]")
macrotab$F1 = paste0(macro$F1, " [", macro$F1CiLow, ",", macro$F1CiUp, "]")
#calculate macro accuracy
macroAcc = round(confusionMatrix(val_6cat$true_label, val_6cat$predicted_label)$overall[c("Accuracy", "AccuracyLower", "AccuracyUpper")],2)
#add Acc to table
macrotab$Acc = paste0(macroAcc[[1]], " [", macroAcc[[2]], ",", macroAcc[[3]], "]")
macrotab_test = macrotab

#validation set
cis_BERT_6cat_validation = round(cis_BERT_6cat_validation, 2)
macro = cis_BERT_6cat_validation["macro",]
macrotab = data.frame(matrix(NA, nrow = 1, ncol = 4))
names(macrotab ) = c("Pr", "Re", "F1", "Acc")
macrotab$Pr = paste0(macro$Precision, " [", macro$PrCiLow, ",", macro$PrCiUp, "]")
macrotab$Re = paste0(macro$Recall, " [", macro$ReCiLow, ",", macro$ReCiUp, "]")
macrotab$F1 = paste0(macro$F1, " [", macro$F1CiLow, ",", macro$F1CiUp, "]")
#calculate macro accuracy
macroAcc = round(confusionMatrix(val_6cat$true_label, val_6cat$predicted_label)$overall[c("Accuracy", "AccuracyLower", "AccuracyUpper")],2)
#add to table
macrotab$Acc = paste0(macroAcc[[1]], " [", macroAcc[[2]], ",", macroAcc[[3]], "]")
macrotab_validation = macrotab
#empty dataframe with colume names for Table 3
tab3 = cbind(macrotab_validation, macrotab_test)
row.names(tab3) = "BERT"
```

## About suicide 

### BERT test set


```{r}
#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 2, ncol = 9), row.names =levels(test_aboutsuicide$true_label))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  

#now run the bootstrap and calculate CIs for each class
for(iclass in levels(test_aboutsuicide$true_label)){
 
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(test_aboutsuicide, mlperf2.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
}

df["macro",] = colMeans(df)
df
cis_BERT_aboutsuicide_test = df
write.csv(cis_BERT_aboutsuicide_test, "../results/cis_BERT_aboutsuicide_test.csv")

```

### BERT validation set

```{r}

#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 2, ncol = 9), row.names =levels(val_aboutsuicide$true_label))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  
#now run the bootstrap and calculate CIs for each class
for(iclass in levels(val_aboutsuicide$true_label)){
 
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(val_aboutsuicide, mlperf2.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
}

df["macro",] = colMeans(df)
df
cis_BERT_aboutsuicide_validation = df
write.csv(cis_BERT_aboutsuicide_validation, "../results/cis_BERT_aboutsuicide_validation.csv")
```



# XLNet: confidence intervals

```{r, read in datafiles XLNet}
val_6cat = order6cat(read.csv('../results/predictions_XLNET_6_classes_validation_set.csv'))
test_6cat = order6cat(read.csv('../results/predictions_XLNET_6_classes_test_set.csv'))
val_aboutsuicide = read.csv('../results/predictions_XLNET_about_suicide_validation_set.csv')
test_aboutsuicide = read.csv('../results/predictions_XLNET_about_suicide_test_set.csv')
```

## 6 categories

### XLNet test set

```{r}
#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 6, ncol = 9), row.names =c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant"))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  
#now run the bootstrap and calculate CIs for each class
for(iclass in c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant")){
 
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(test_6cat,mlperf6.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
}

df["macro",] = colMeans(df)
df
cis_XLNet_6cat_test = df
write.csv(cis_XLNet_6cat_test, "../results/cis_XLNet_6cat_test.csv")
```

### XLNet validation set

```{r}
#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 6, ncol = 9), row.names =c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant"))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  
#now run the bootstrap and calculate CIs for each class
for(iclass in c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant")){
 
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(val_6cat,mlperf6.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
}
df["macro",] = colMeans(df)
df
cis_XLNet_6cat_validation = df
write.csv(cis_XLNet_6cat_validation, "../results/cis_XLNet_6cat_validation.csv")
```

```{r}
#format to paste into tables in paper: the macro averages tables 3 and 5: validation set | test set, one metric per column
# test set
cis_XLNet_6cat_test = round(cis_XLNet_6cat_test, 2)
macro = cis_XLNet_6cat_test["macro",]
#empty dataframe with colume names
macrotab = data.frame(matrix(NA, nrow = 1, ncol = 4))
names(macrotab ) = c("Pr", "Re", "F1", "Acc")
#paste the precision and its CI values into one cell, then same for recall and F1
macrotab$Pr = paste0(macro$Precision, " [", macro$PrCiLow, ",", macro$PrCiUp, "]")
macrotab$Re = paste0(macro$Recall, " [", macro$ReCiLow, ",", macro$ReCiUp, "]")
macrotab$F1 = paste0(macro$F1, " [", macro$F1CiLow, ",", macro$F1CiUp, "]")
#calculate macro accuracy
macroAcc = round(confusionMatrix(val_6cat$true_label, val_6cat$predicted_label)$overall[c("Accuracy", "AccuracyLower", "AccuracyUpper")],2)
#add Acc to table
macrotab$Acc = paste0(macroAcc[[1]], " [", macroAcc[[2]], ",", macroAcc[[3]], "]")
macrotab_test = macrotab

#validation set
cis_XLNet_6cat_validation = round(cis_XLNet_6cat_validation, 2)
macro = cis_XLNet_6cat_validation["macro",]
macrotab = data.frame(matrix(NA, nrow = 1, ncol = 4))
names(macrotab ) = c("Pr", "Re", "F1", "Acc")
macrotab$Pr = paste0(macro$Precision, " [", macro$PrCiLow, ",", macro$PrCiUp, "]")
macrotab$Re = paste0(macro$Recall, " [", macro$ReCiLow, ",", macro$ReCiUp, "]")
macrotab$F1 = paste0(macro$F1, " [", macro$F1CiLow, ",", macro$F1CiUp, "]")
#calculate macro accuracy
macroAcc = round(confusionMatrix(val_6cat$true_label, val_6cat$predicted_label)$overall[c("Accuracy", "AccuracyLower", "AccuracyUpper")],2)
#add to table
macrotab$Acc = paste0(macroAcc[[1]], " [", macroAcc[[2]], ",", macroAcc[[3]], "]")
macrotab_validation = macrotab
#empty dataframe with colume names for Table 3
tab3 = rbind(tab3, cbind(macrotab_validation, macrotab_test))
row.names(tab3)[2] = "XLNet"
```


## About suicide 

### XLNet test set

```{r}
#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 2, ncol = 9), row.names =levels(test_aboutsuicide$true_label))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  

#now run the bootstrap and calculate CIs for each class
for(iclass in levels(test_aboutsuicide$true_label)){
 
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(test_aboutsuicide, mlperf2.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
}

df["macro",] = colMeans(df)
df
cis_XLNet_aboutsuicide_test = df
write.csv(cis_XLNet_aboutsuicide_test, "../results/cis_XLNet_aboutsuicide_test.csv")
```

### XLNet validation set

```{r}
#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 2, ncol = 9), row.names =levels(val_aboutsuicide$true_label))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  

#now run the bootstrap and calculate CIs for each class
for(iclass in levels(val_aboutsuicide$true_label)){
 
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(val_aboutsuicide, mlperf2.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
}

df["macro",] = colMeans(df)
df
cis_XLNet_aboutsuicide_validation = df
write.csv(cis_XLNet_aboutsuicide_validation, "../results/cis_XLNet_aboutsuicide_validation.csv")
```

# TFIDF: Performance scores with confidence intervals

```{r, read in datafiles TFIDF}
val_6cat = order6cat(read.csv('../results/predictions_TFIDF_6_classes_validation_set.csv'))
test_6cat = order6cat(read.csv('../results/predictions_TFIDF_6_classes_test_set.csv'))
val_aboutsuicide = read.csv('../results/predictions_TFIDF_about_suicide_validation_set.csv')
test_aboutsuicide = read.csv('../results/predictions_TFIDF_about_suicide_test_set.csv')
```

## 6 categories

### TFIDF test set

```{r}
#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 6, ncol = 9), row.names =c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant"))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  
#now run the bootstrap and calculate CIs for each class
for(iclass in c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant")){
 
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(test_6cat,mlperf6.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
}

df["macro",] = colMeans(df)
df
cis_TFIDF_6cat_test = df
write.csv(cis_TFIDF_6cat_test, "../results/cis_TFIDF_6cat_test.csv")
```

### TFIDF validation set

```{r}
#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 6, ncol = 9), row.names =c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant"))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  
#now run the bootstrap and calculate CIs for each class
for(iclass in c("suicidality", 'coping', "awareness", "prevention", "werther", "irrelevant")){
 
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(val_6cat,mlperf6.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
}
df["macro",] = colMeans(df)
df
cis_TFIDF_6cat_validation = df
write.csv(cis_TFIDF_6cat_validation, "../results/cis_TFIDF_6cat_validation.csv")
```

## About suicide 

### TFIDF test set

```{r}
#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 2, ncol = 9), row.names =levels(test_aboutsuicide$true_label))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  

#now run the bootstrap and calculate CIs for each class
for(iclass in levels(test_aboutsuicide$true_label)){
 
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(test_aboutsuicide, mlperf2.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
}

df["macro",] = colMeans(df)
df
cis_TFIDF_aboutsuicide_test = df
write.csv(cis_TFIDF_aboutsuicide_test, "../results/cis_TFIDF_aboutsuicide_test.csv")
```

### TFIDF validation set

```{r}

#create empty dataframe for all metrics plus CI
df = data.frame(matrix(NA, nrow = 2, ncol = 9), row.names =levels(val_aboutsuicide$true_label))
names(df) =  c("Precision", "PrCiLow", "PrCiUp","Recall","ReCiLow", "ReCiUp", "F1", "F1CiLow", "F1CiUp")
  

#now run the bootstrap and calculate CIs for each class
for(iclass in levels(val_aboutsuicide$true_label)){
 
  #calculate metrics in 1000 bootstrapped samples
  set.seed(42)
  bootstrap = boot(val_aboutsuicide, mlperf2.fun, class=iclass, R=1000)
  
  #save the bootstrapped statistics into dataframe, the row for iclass
  df[iclass, c("Precision", "Recall", "F1")] = bootstrap$t0
  
  #calculate ci's for each metric (index 1, 2, 3)
  precision_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=1)
  df[iclass, c("PrCiLow", "PrCiUp")] = c(precision_ci$normal[[2]], precision_ci$normal[[3]])
  recall_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=2)
  df[iclass, c("ReCiLow", "ReCiUp")] = c(recall_ci$normal[[2]],recall_ci$normal[[3]])
  f1_ci = boot.ci(boot.out = bootstrap, type = c("norm"), index=3)
  df[iclass, c("F1CiLow", "F1CiUp")] = c(f1_ci$normal[[2]], f1_ci$normal[[3]])
}
  
df["macro",] = colMeans(df)
df
cis_TFIDF_aboutsuicide_validation = df
write.csv(cis_TFIDF_aboutsuicide_validation, "../results/cis_TFIDF_aboutsuicide_validation.csv")
```

