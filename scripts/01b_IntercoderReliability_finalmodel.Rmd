---
title: "Final intercoder reliability"
author: "Hannah Metzler"
date: "9/21/2021"
output: 
  pdf_document:
    df_print: kable
    keep_tex: true
url_colour: blue
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
Sys.setlocale("LC_ALL", 'en_US.UTF-8')
options(scipen=99)
library(dplyr)
library(stringr)
library(tidyr)
library(DescTools) #for cohen's kappa instead of irr - change in paper
library(janitor) #for viewing duplicates
library(caret) #confusionMatrix
library(cocron)
```

# Final reliability round 4: 150 predicted with BERT for 5 main categories of interest

Codes by Hannah and Thomas and BERT used for the final results. Coding into the 1 small categories, but simplify to 5 main categories (Coping, Suicidality, Awareness, Prevention, Werther) before evaluating the reliability. No evaluation for the irrelevant class. 

Goal was to have at least 100 true instances for each class. 

```{r, preprocess data BERT and Hannah}
#Load and clean the data

#BERT predictions
db4 <- read.csv('../reliability_datasets/round4_150x5_suicide_withpredictions_BERT_finetuned.csv', stringsAsFactors = F, sep = '\t',  colClasses = "character") %>% 
  mutate(BERT_best_new = as.factor(BERT_best_new),
         predictionBERT1 = as.factor(predictionBERT1),
         predictions_about_suicide = as.factor(predictions_about_suicide),
         id = as.character(id)) %>% 
  rename(main_category.BERT = BERT_best_new, 
         about_suicide.BERT = predictions_about_suicide) %>% 
  #delete column with rownumbers
  select(-X) %>% 
  #recode the levels of about suicide to No and Yes
  mutate(about_suicide.BERT = recode(about_suicide.BERT, correct="Yes", false="No"))
# select(-predictionBERT1) #these are predictions by a previous, less good version of our model


#Hannah's labels
dh4 <- read.csv('../reliability_datasets/round4_150x5_suicide_Hannah_complete_IDsrepaired.csv', stringsAsFactors = T,  colClasses = "character")  %>% 
  #delete text columns, messed up by excel, use text from BERT predictions dataset. #delete text columns split into multiple columns in Hannah file
  select(-c(text, X, X.1, X.2, X.3, X.4, X.5, X.6)) %>% 
  #transform to factor
  mutate(notserious_unclear = as.factor(notserious_unclear), 
         focus = as.factor(focus), 
         type = as.factor(type), 
         category = as.factor(category),
         category2 = as.factor(category2)) %>%
  mutate(time = as.character(time), 
         id = as.character(id)) %>% 
  mutate(main_category = recode(category, 
                                news_suicidality = "irrelevant", news_coping = "irrelevant", 
                                bereaved_negative = "irrelevant", bereaved_coping = "irrelevant", 
                                life_saved = "irrelevant", suicide_other = "irrelevant", "off-topic" = "irrelevant", 
                                coping1 = "coping", coping3 = "coping", suicidality1 = "suicidality", suicidality3 = "suicidality"))
```


```{r, preprocess data Thomas}
#Thomas' labels
dt4 <- read.csv('../reliability_datasets/round4_150x5_suicide_Thomas_complete_IDsrepaired.csv', stringsAsFactors = F, sep = '\t',  colClasses = "character") %>% 
  select(-X1.problem.1) %>% 
  #delete text columns, messed up by excel, use text from BERT predictions dataset. #delete text columns split into multiple columns in Hannah file
  select(-c(text, text.1, X, X.1, X.2, X.3, X.4, X.5, X.6)) %>% 
  rename(notes.thomas = "any.other.category.", 
         focus0 = "Focus.0..neither.problem.solution", 
         focus1 = "X1.problem", 
         focus2 = "X2.solution", 
         notserious_unclear1 = "notserious_unclear..1..includes.suicide_other.and.off.topic") %>% 
  #transform logical vectors to characters
  mutate(news.coping  = as.character(news.coping), 
         id = as.character(id))  %>% 
  
  
  # #check for empty labels in Thomas' dataset, first for the columns belonging to the variable category
  # allcats = unite(dt4, allcats, Suicidality.1:off.topic, sep="_")$allcats
  # allfocus = unite(dt4, allfocus, focus0:focus2, sep="_")$allfocus
  # allnotserious = unite(dt4, allnotserious, notserious_unclear1:X0.serious, sep="_")$allnotserious
  # #now label rows that do not contain an X as false
  # dt4$emptycategory = !str_detect(allcats, "x")
  # dt4$emptyfocus = !str_detect(allfocus, "x")
  # dt4$emptynotserious = !str_detect(allnotserious, "x")
  # #replace these empty categories with NaN
# 
# #empty labels saved in this dataset, it was mostly focus labels missing, completed
# d = dt4 %>% filter(emptycategory == TRUE | emptyfocus == TRUE | emptynotserious == TRUE)
# # write.csv2(file="../results/empty_labels_reliability_round4_Thomas.csv",d, row.names=F)


#rename x in all category columns to the name of the category, so they can all be merged into one column next
mutate(Suicidality.1 = recode(Suicidality.1, x="suicidality1"), 
       Suicidality.3 = recode(Suicidality.3, x="suicidality3"), 
       Coping.1  = recode(Coping.1, x = "coping1"),
       Coping.3  = recode(Coping.3, x = "coping3" ),
       bereaved.neg  = recode(bereaved.neg, x = "bereaved_negative"), 
       bereaved.pos  = recode(bereaved.pos, x = "bereaved_coping"),
       werther  = recode(werther, x = "werther"),
       awareness  = recode(awareness, x = "awareness"), 
       prevention  = recode(prevention, x ="prevention"), 
       live.saved  = recode(live.saved, x ="life_saved"), 
       news.suicidality  = recode(news.suicidality, x ="news_suicidality"), 
       prevention  = recode(prevention, x ="prevention"), 
       news.coping  = recode(news.coping, x ="news_coping"), 
       sui.other  = recode(sui.other, x ="suicide_other"), 
       off.topic   = recode(off.topic , x ="off-topic")) %>% 
  #combine all above columns into one variable called category
  tidyr::pivot_longer(cols=c("Suicidality.1", "Suicidality.3", 
                             "Coping.1", "Coping.3", "bereaved.neg", "bereaved.pos", "werther", 
                             "live.saved", "awareness", "prevention", "news.suicidality", 
                             "news.coping", "sui.other", "off.topic"), names_to="variable", values_to="category") %>% 
  mutate(category = as.factor(category)) %>% 
  
  # #this issue was fixed by completing the empty labels in Thomas' dataset
  # # # we now have 570*14 rows, each row repeated per category. Keep only the row with an entry
  # # # there should be 13 empty ones per tweet, ie. 750*13=  9750, there are 9752 if we count NAs (all lines for news.coping) and empty "". i.e. 2 more empty ones than there should be. 
  # xtabs(~category, dt4)
  # sum(is.na(dt4$category)) #750 NAs, 
  # dt4[is.na(dt4$category), ]#all from the category news.coping. i.e. no tweet for news coping
  
  filter(category != "") %>% 
  select(-variable) %>% 
  
  #repeat the same for the 3 focus variables: recode the cells to column name
  mutate(focus0 = recode(focus0, x="0"),
         focus1= recode(focus1, x= "1"), 
         focus2= recode(focus2, x = "2")) %>% 
  #merge all into 1 column  
  tidyr::pivot_longer(cols=c("focus0", "focus1", "focus2"), names_to="variable", values_to="focus") %>% 
  filter(focus != "") %>% 
  select(-variable) %>% 
  # #here we had 2 duplicates, because Thomas' file contained duplicate focus labels for 2 Tweets: 994362285744443392, 1173390237801820161. 1 label deleted for each tweet. 
  # janitor::get_dupes(dt4, id)
  
  #repeat the same for serious/unclear: recode the cells to column name
  mutate(notserious_unclear1 = recode(notserious_unclear1, x="1"),
         X0.serious= recode(X0.serious, x= "0")) %>% 
  #merge all into 1 column
  tidyr::pivot_longer(cols=c("notserious_unclear1", "X0.serious"), names_to="variable", values_to="notserious_unclear") %>% 
  select(-variable) %>% 
  filter(notserious_unclear != "") %>% 
  
  #format variables
  mutate(notserious_unclear = as.factor(notserious_unclear), 
         focus = as.factor(focus), 
         category = as.factor(category)) %>% 
  mutate(time = as.character(time), 
         id = as.character(id)) %>% 
  #create main category variable
  mutate(main_category = as.factor(recode(category, news_suicidality = "irrelevant", news_coping = "irrelevant", bereaved_negative = "irrelevant", bereaved_coping = "irrelevant", 
                                          life_saved = "irrelevant", suicide_other = "irrelevant", "off-topic" = "irrelevant", 
                                          coping1 = "coping", coping3 = "coping", suicidality1 = "suicidality", suicidality3 = "suicidality"))) %>% 
  droplevels() #delete the empty levels
# # #here we had 2 duplicates, because Thomas' file contained duplicate seriousvsnot labels for 1 tweet. 613152024935460864. 1 was deleted. 
# janitor::get_dupes(dt4, id)
```


```{r, join dataframes}
#join Hannah and BERT
d4 = db4 %>% 
  inner_join(dh4, suffix = c(".bert", ".hannah"), by = "id") %>% 
  inner_join(dt4, suffix = c(".hannah", ".thomas"), by = "id") %>% 
  #keep only time column from Bert dataset
  select(-c(time, time.hannah)) %>% 
  rename(notes.hannah = ambiguous, 
         type.hannah = type, 
         time = time.bert, 
         category2.hannah = category2) %>% 
  mutate(category2.hannah = na_if(category2.hannah,"")) %>% 
  #create a category variable with all 14 levels, including the perspective 1 and 2 for coping and suicidal tweets
  rename(detailed_category.hannah =  category.hannah, 
         detailed_category.thomas= category.thomas) %>% 
  #reduce 14 levels to 12 for the category variable
  mutate( category.hannah  = recode(detailed_category.hannah,  coping1 = "coping", coping3 = "coping", suicidality1 = "suicidality", suicidality3 = "suicidality" ), 
           category.thomas  = recode(detailed_category.thomas,  coping1 = "coping", coping3 = "coping", suicidality1 = "suicidality", suicidality3 = "suicidality" ))
#order columns
d4 = d4[, c("id", "time", "text", 
            "main_category.BERT", "predictionBERT1", 
            "main_category.hannah",  "main_category.thomas", 
            "category.hannah", "category.thomas", 
            "category2.hannah", "detailed_category.hannah", 
            "focus.hannah", "focus.thomas",   "type.hannah",
            "notserious_unclear.hannah", "notserious_unclear.thomas", 
            "notes.hannah", "notes.thomas", 
              "about_suicide.BERT")]

#order factor levels of main category
#order of categories for plots
ord_mcategory= c( "suicidality", "coping", "awareness", "prevention", "werther", "irrelevant")
d4 = d4 %>% 
  mutate(main_category.hannah = factor(main_category.hannah, levels = ord_mcategory, labels = ord_mcategory), 
         main_category.thomas = factor(main_category.thomas, levels = ord_mcategory, labels = ord_mcategory), 
         main_category.BERT = factor(main_category.BERT, levels = ord_mcategory, labels = ord_mcategory), 
         # add variable about suicide vs not (off-topic vs. other categories)
         about_suicide.hannah = factor(if_else(category.hannah == "off-topic", 0, 1), labels = c("No", "Yes")), 
         about_suicide.thomas = factor(if_else(category.thomas == "off-topic", 0, 1), labels = c("No", "Yes")))

#order factors in separate dataframes
db4 = db4 %>% 
  mutate(main_category.BERT = factor(main_category.BERT, levels = ord_mcategory, labels = ord_mcategory))
dh4 = dh4 %>% 
  mutate(main_category = factor(main_category, levels = ord_mcategory, labels = ord_mcategory))
dt4 = dt4 %>% 
  mutate(main_category = factor(main_category, levels = ord_mcategory, labels = ord_mcategory))

#filter (remove) the irrelevant category for calculating Kappa (only predictions for 5 relevant ones included in BERT)
d4r = d4 %>%  #data round 4 relevant categories only
  filter(main_category.hannah != "irrelevant") %>% 
  filter(main_category.thomas != "irrelevant") %>% 
  filter(main_category.BERT != "irrelevant") %>%
  droplevels()
```

```{r}
summary(d4)
```


# How many true labels do we have per category? 

In total: `r nrow(db4)`

Bert's labels: 

```{r}
xtabs(~main_category.BERT, db4)
```

Hannah's labels: 
```{r}
xtabs(~main_category, dh4)

```

Thomas' labels: 
```{r}
xtabs(~main_category, dt4)
```

```{r, missing data}
# #join missing labels and duplicate labels with new awareness tweet candidates - thomas has now provided these missing labels
# missing_ids = read.csv("../results/empty_labels_reliability_round4_Thomas.csv", colClasses = "character")$id
# dupe_ids = c("994362285744443392", "1173390237801820161", "613152024935460864")
# d = d4 %>% 
#   filter(id %in% dupe_ids | id %in% missing_ids) %>% 
#   select( c("id", "category.thomas", "focus.thomas", "notserious_unclear.thomas", "notes.thomas", "text"))
# write.table(file="../results/labels_thomas_missing_duplicates.tsv", d, sep="\t", row.names = F)

```


# Detailed content categories (6-12 classes)
## Hannah (coder 1) and BERT

### 6 categories (including irrelevant)

```{r}
caret::confusionMatrix(d4$main_category.BERT, d4$main_category.hannah)
round(DescTools::CohenKappa(d4$main_category.BERT, d4$main_category.hannah, conf.level = 0.95), 2)
```

###  5 categories with new finetuned BERT model

```{r}
caret::confusionMatrix(d4r$main_category.BERT, d4r$main_category.hannah)
# #for 5 categoriew with previous BERT model, not finetuned
# caret::confusionMatrix(d4r$predictionBERT1, d4r$main_category.hannah)
round(DescTools::CohenKappa(d4r$main_category.BERT, d4r$main_category.hannah, conf.level = 0.95), 2)
```

### Analysis of confusion matrix: 

- model mistakes 11 out of 110 coping tweets as suicidality. Are these the past suicidality tweets?

```{r}
d4 %>% 
  filter(main_category.hannah == "coping" & main_category.bert)
```


## Thomas (coder 2) and BERT

6 classes (including irrelevant)

```{r}
confusionMatrix(d4$main_category.BERT, d4$main_category.thomas)
round(DescTools::CohenKappa(d4$main_category.BERT, d4$main_category.thomas, conf.level = 0.95), 2)
```

5 classes (excluding irrelevant)
```{r}
confusionMatrix(d4r$main_category.BERT, d4r$main_category.thomas)
round(DescTools::CohenKappa(d4r$main_category.BERT, d4r$main_category.thomas, conf.level = 0.95), 2)
```


## Human inter-coder reliability

### 6 main categories (including irrelevant)
```{r}
round(confusionMatrix(d4$main_category.hannah, d4$main_category.thomas)$overall, 2)
round(DescTools::CohenKappa(d4$main_category.hannah, d4$main_category.thomas, conf.level = 0.95), 2)
```

###  5 categories of interest

```{r}
confusionMatrix(d4r$main_category.hannah, d4r$main_category.thomas)
round(DescTools::CohenKappa(d4r$main_category.hannah, d4r$main_category.thomas, conf.level = 0.95), 2)
```

### 12 categories

```{r}
#details on cohen's kappa, unweighted: https://www.datanovia.com/en/lessons/cohens-kappa-in-r-for-two-categorical-variables/
DescTools::CohenKappa(d4$category.hannah, y = d4$category.thomas, conf.level = 0.95)
```


# Summarize 6 category results for paper Table 4

```{r}
byclass = data.frame(
  pair = c(rep("Coder 1 - BERT", 3), rep("Coder 2 - BERT", 3), rep("Coder 1 - Coder 2", 3)),
  rbind(
    round(t(caret::confusionMatrix(d4$main_category.BERT, d4$main_category.hannah)$byClass[,c("Precision", "Recall", "F1")]),2),
    round(t(caret::confusionMatrix(d4$main_category.BERT, d4$main_category.thomas)$byClass[,c("Precision", "Recall", "F1")]),2),
    round(t(caret::confusionMatrix(d4$main_category.hannah, d4$main_category.thomas)$byClass[,c("Precision", "Recall", "F1")]),2)
  )
)
#order by metric
byclass = byclass[ order((row.names(byclass))), ]
byclass
# write.csv(file = "../results/inter-rater-reliability.csv", byclass)
```

```{r, save dataset with predictions and human labels}
save(d4, file  = '../reliability_datasets/round4_150x5_suicide_human&model_BERT_finetuned.R')
```


# 2 categories: About actual suicide vs. off-topic

## Macro-average performance across both categories: 

### Hannah (coder 1) & BERT

```{r}
caret::confusionMatrix(d4$about_suicide.BERT, d4$about_suicide.hannah, positive="Yes")$table
round(caret::confusionMatrix(d4$about_suicide.BERT, d4$about_suicide.hannah, positive="Yes")$overall[c("Accuracy", "Kappa")],2)
round(DescTools::CohenKappa(d4$about_suicide.BERT, d4$about_suicide.hannah, conf.level = 0.95), 2)
```

### Thomas (coder 2) & BERT

```{r}
caret::confusionMatrix(d4$about_suicide.BERT, d4$about_suicide.thomas, positive="Yes")$table
round(caret::confusionMatrix(d4$about_suicide.BERT, d4$about_suicide.thomas, positive="Yes")$overall[c("Accuracy", "Kappa")],2)
round(DescTools::CohenKappa(d4$about_suicide.BERT, d4$about_suicide.thomas, conf.level = 0.95), 2)
```

### Human inter-rater reliability

```{r}
caret::confusionMatrix(d4$about_suicide.hannah, d4$about_suicide.thomas, positive="Yes")$table
round(caret::confusionMatrix(d4$about_suicide.hannah, d4$about_suicide.thomas, positive="Yes")$overall[c("Accuracy", "Kappa")],2)
round(DescTools::CohenKappa(d4$about_suicide.hannah, d4$about_suicide.thomas, conf.level = 0.95), 2)
```


## Macro-average without the category suicide other: 

### Hannah (coder 1) & BERT

```{r}
d4_no_other = d4 %>% 
  filter(category.hannah !="suicide_other")
caret::confusionMatrix(d4_no_other$about_suicide.BERT, d4_no_other$about_suicide.hannah, positive="Yes")$table
round(caret::confusionMatrix(d4_no_other$about_suicide.BERT, d4_no_other$about_suicide.hannah, positive="Yes")$overall[c("Accuracy", "AccuracyUpper", "AccuracyLower")],2)
round(DescTools::CohenKappa(d4_no_other$about_suicide.BERT, d4_no_other$about_suicide.hannah, conf.level = 0.95), 2)
```

### Thomas (coder 2) & BERT

```{r}
d4_no_other = d4 %>% 
  filter(category.hannah !="suicide_other")
caret::confusionMatrix(d4_no_other$about_suicide.BERT, d4_no_other$about_suicide.thomas, positive="Yes")$table
round(caret::confusionMatrix(d4_no_other$about_suicide.BERT, d4_no_other$about_suicide.thomas, positive="Yes")$overall[c("Accuracy", "AccuracyUpper", "AccuracyLower")],2)
round(DescTools::CohenKappa(d4_no_other$about_suicide.BERT, d4_no_other$about_suicide.thomas, conf.level = 0.95), 2)
```

### Human inter-rater reliability

```{r}
d4_no_other = d4 %>% 
  filter(category.hannah !="suicide_other")
caret::confusionMatrix(d4_no_other$about_suicide.hannah, d4_no_other$about_suicide.thomas, positive="Yes")$table
round(caret::confusionMatrix(d4_no_other$about_suicide.hannah, d4_no_other$about_suicide.thomas, positive="Yes")$overall[c("Accuracy", "AccuracyUpper", "AccuracyLower")],2)
round(DescTools::CohenKappa(d4_no_other$about_suicide.hannah, d4_no_other$about_suicide.thomas, conf.level = 0.95), 2)
```


## Per category: About suicide

### Hannah (coder 1) & BERT

```{r}
round(caret::confusionMatrix(d4$about_suicide.BERT, d4$about_suicide.hannah, positive="Yes")$byClass[c("Precision", "Recall", "F1")], 2)
```

### Thomas (coder 2) & BERT

```{r}
round(caret::confusionMatrix(d4$about_suicide.BERT, d4$about_suicide.thomas, positive="Yes")$byClass[c("Precision", "Recall", "F1")], 2)
```

### Human inter-rater reliability

```{r}
round(caret::confusionMatrix(d4$about_suicide.hannah, d4$about_suicide.thomas, positive="Yes")$byClass[c("Precision", "Recall", "F1")], 2)
```

## Per category: Off-topic 

### Hannah (coder 1) & BERT
```{r}
round(caret::confusionMatrix(d4$about_suicide.BERT, d4$about_suicide.hannah, positive="No")$byClass[c("Precision", "Recall", "F1")], 2)
```
### Thomas (coder 2) & BERT
```{r}
round(caret::confusionMatrix(d4$about_suicide.BERT, d4$about_suicide.thomas, positive="No")$byClass[c("Precision", "Recall", "F1")], 2)
```
### Human inter-rater reliability
```{r}
round(caret::confusionMatrix(d4$about_suicide.hannah, d4$about_suicide.thomas, positive="No")$byClass[c("Precision", "Recall", "F1")], 2)
```

